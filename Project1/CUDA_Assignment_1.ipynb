{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "F5bwyWnO0Zqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5wFclIcJ1ILe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Download train and test data from URL\n",
        "!wget https://pjreddie.com/media/files/mnist_train.csv\n",
        "!wget https://pjreddie.com/media/files/mnist_test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3JggT78i1LfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load the data into array\n",
        "train_data = np.loadtxt('mnist_train.csv', dtype=float, delimiter=\",\")\n",
        "test_data = np.loadtxt('mnist_test.csv', dtype=float, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BByHjQcs2jcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#slice the data to seperate data & labels\n",
        "x_train_data=train_data[:, 1:]\n",
        "x_train_labels=train_data[:, :1]\n",
        "x_test_data=test_data[:, 1:]\n",
        "x_test_labels=test_data[:, :1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "59spR9NA6J65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#One hot encoding to lables\n",
        "import numpy as np\n",
        "lr = np.arange(10)\n",
        "for label in range(10):\n",
        "    one_hot = (lr==label).astype(np.int)\n",
        "    print(\"label: \", label, \" in one-hot representation: \", one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XdwFHwTg6UbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = np.arange(10)\n",
        "# transform labels into one hot representation\n",
        "train_labels_one_hot = (lr==x_train_labels).astype(np.int)\n",
        "test_labels_one_hot = (lr==x_test_labels).astype(np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtZBpFB66XaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#2 layer Neural network code \n",
        "np.random.seed(4)\n",
        "#Weight matrix of size 784x10\n",
        "W = 2*np.random.random((784,10))-1\n",
        "bias = 0 \n",
        "learnrate = 0.05\n",
        "\n",
        "#defining softmax function as activation function\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "#defining a function to convert the output to an array of 0 & 1 where the max prob is set to 1\n",
        "def MaxSetTo1(x):\n",
        "    b = np.zeros_like(x)\n",
        "    b[np.arange(len(x)), x.argmax(1)] = 1\n",
        "    return b  \n",
        "\n",
        "\n",
        "#defining a for loop from 1 to 60000 where the batch size is 20\n",
        "for i in range(1,60000,20):\n",
        "  print(i)\n",
        "  l0 = x_train_data[i:i+20,:]\n",
        "  l1 = softmax(np.dot(l0,W)+bias)\n",
        "  \n",
        "  #To calculate MSE\n",
        "  l1_error = np.square(np.subtract(train_labels_one_hot[i:i+20,:], l1)).mean()\n",
        "  l1_delta = l1_error * softmax(l1)*learnrate\n",
        "  W += np.dot(l0.T,l1_delta)\n",
        "  \n",
        "\n",
        "  print(\"Output After Training:\")\n",
        "  print(MaxSetTo1(l1))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Viktdhu36kiO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Testing the network\n",
        "result=softmax(np.dot(x_test_data,W)+bias)\n",
        "print(MaxSetTo1(result))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}