{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwB3ZCg_CRbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import matplotlib.pyplot as plt \n",
        "if torch.cuda.is_available():\n",
        "    avDev = torch.device(\"cuda\")\n",
        "else:\n",
        "    avDev = torch.device(\"cpu\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AqtXuNK30Xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size = 200\n",
        "n_iters = 2500\n",
        "num_epochs = n_iters / (len(trainset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "#DataLoading and making it iterable\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        " \n",
        "test_loader = torch.utils.data.DataLoader(dataset=testset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNtkjuvOYT5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model class\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dim, 190)\n",
        "        self.linear2 = nn.Linear(190, output_dim)\n",
        "        self.relu = nn.Sigmoid()\n",
        "     \n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.linear1(x))\n",
        "        out = self.linear2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojsTtynQYyiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining input and output dimensions\n",
        "input_dim = 3*32*32\n",
        "output_dim = 10\n",
        " \n",
        "model = LogisticRegressionModel(input_dim, output_dim)\n",
        "model.to(avDev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOwrUd20bZZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#loss class\n",
        "criterion = nn.CrossEntropyLoss().to(avDev)\n",
        "\n",
        "best_val=0\n",
        "\n",
        "#specifying learning rate range to choose the best one\n",
        "learning_rates = [0.01,0.3]\n",
        "#finding the best learning rate\n",
        "for learning_rate in np.linspace(learning_rates[0], learning_rates[1], num = 5):\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    print('Learning rate: {}.'.format(learning_rate))\n",
        "    iter = 0\n",
        "    acc_plt=[0]\n",
        "    confusion_matrix=np.zeros( (10, 10) )\n",
        "    for epoch in range(num_epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "         \n",
        "        #training the data\n",
        "        image =  images.view(-1, 3*32*32).to(avDev)\n",
        "        label = labels.to(avDev)\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "         \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(image)\n",
        "         \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, label)#\n",
        "         \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "         \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "        acc_plt\n",
        "        iter += 1\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                \n",
        "                images = images.view(-1, 3*32*32).to(avDev)\n",
        "              #  kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
        "              #  results = model_selection.cross_val_score(model, X, Y, cv=kfold) \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "                 \n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                 \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)                 \n",
        "               \n",
        "                # Total correct predictions\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
        "                \n",
        "                #defining confusion matrix\n",
        "                for i in range(100):\n",
        "                  confusion_matrix[predicted[i]][labels[i]]+=1\n",
        "            #Accuracy calculation  \n",
        "            accuracy = 100. * correct / total\n",
        "            acc_plt.append(accuracy)\n",
        "            \n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
        "            \n",
        "            \n",
        "    val_acc=np.max(acc_plt)\n",
        "    if val_acc > best_val:\n",
        "       best_val = val_acc\n",
        "       best_lr = learning_rate\n",
        "       best_acc_plt=acc_plt\n",
        "        \n",
        "print('Best accurancy: {} and Best learning rate: {}'.format(best_val,best_lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7SU_vH4M45T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Confusion Matrix:')\n",
        "confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT91jIG5Ok4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Learning Curve\n",
        "acc_plt\n",
        "test_set=np.linspace(0,10000,6)\n",
        "plt.plot(test_set,acc_plt)\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.xlabel(\"Test Set Size\"), plt.ylabel(\"Accuracy Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi4seTtN9voz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}